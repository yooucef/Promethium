{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Deep Learning: U-Net Reconstruction\n",
                "\n",
                "This notebook demonstrates using deep learning models for seismic reconstruction.\n",
                "\n",
                "**Prerequisites:**\n",
                "- Python 3.10+\n",
                "- PyTorch basics\n",
                "- GPU recommended\n",
                "\n",
                "**Estimated Runtime:** 10 minutes (CPU), 3 minutes (GPU)\n",
                "\n",
                "**Topics Covered:**\n",
                "- U-Net architecture overview\n",
                "- Model loading and inference\n",
                "- Batch processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment to install:\n",
                "# !pip install promethium-seismic==1.0.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import promethium\n",
                "from promethium import (\n",
                "    SeismicRecoveryPipeline,\n",
                "    get_model,\n",
                "    run_recovery,\n",
                "    InferenceEngine,\n",
                "    generate_synthetic_traces,\n",
                "    add_noise,\n",
                "    evaluate_reconstruction,\n",
                "    set_seed,\n",
                "    get_device,\n",
                ")\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(f\"Promethium version: {promethium.__version__}\")\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "\n",
                "set_seed(42)\n",
                "device = get_device()\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. U-Net Architecture Overview\n",
                "\n",
                "The U-Net is an encoder-decoder architecture with skip connections:\n",
                "\n",
                "```\n",
                "Input -> Encoder (downsample) -> Bottleneck -> Decoder (upsample) -> Output\n",
                "           |___________________Skip Connections_________________|\n",
                "```\n",
                "\n",
                "**Key Properties:**\n",
                "- Preserves spatial information via skip connections\n",
                "- Captures multi-scale features\n",
                "- Effective for denoising and interpolation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Create Test Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate clean and noisy data\n",
                "clean_data, metadata = generate_synthetic_traces(\n",
                "    n_traces=64,\n",
                "    n_samples=256,\n",
                "    sample_rate=250.0,\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "noisy_data = add_noise(clean_data, noise_level=0.3, seed=42)\n",
                "\n",
                "print(f\"Data shape: {clean_data.shape}\")\n",
                "print(f\"Clean data range: [{clean_data.min():.3f}, {clean_data.max():.3f}]\")\n",
                "print(f\"Noisy data range: [{noisy_data.min():.3f}, {noisy_data.max():.3f}]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Pre-configured Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View available presets\n",
                "presets = SeismicRecoveryPipeline.list_presets()\n",
                "print(\"Available presets:\")\n",
                "for preset in presets:\n",
                "    print(f\"  - {preset}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load U-Net denoising pipeline\n",
                "try:\n",
                "    pipeline = SeismicRecoveryPipeline.from_preset('unet_denoise_v1')\n",
                "    print(f\"Loaded pipeline: {pipeline.model_name}\")\n",
                "    print(f\"Device: {pipeline.device}\")\n",
                "    \n",
                "    # Print model summary\n",
                "    if hasattr(pipeline, 'model') and pipeline.model is not None:\n",
                "        total_params = sum(p.numel() for p in pipeline.model.parameters())\n",
                "        print(f\"Total parameters: {total_params:,}\")\n",
                "except Exception as e:\n",
                "    print(f\"Pipeline loading note: {e}\")\n",
                "    print(\"Using fallback inference for demonstration.\")\n",
                "    pipeline = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run recovery\n",
                "if pipeline is not None:\n",
                "    try:\n",
                "        reconstructed = pipeline.run(noisy_data)\n",
                "        print(f\"Reconstructed shape: {reconstructed.shape}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Inference note: {e}\")\n",
                "        reconstructed = None\n",
                "else:\n",
                "    reconstructed = None\n",
                "\n",
                "# Fallback: demonstrate with simple denoising\n",
                "if reconstructed is None:\n",
                "    print(\"Using demonstration fallback (Gaussian filter)\")\n",
                "    from scipy.ndimage import gaussian_filter1d\n",
                "    reconstructed = np.array([gaussian_filter1d(t, sigma=2) for t in noisy_data])\n",
                "\n",
                "print(f\"Output shape: {reconstructed.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluate Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute metrics\n",
                "noisy_metrics = evaluate_reconstruction(clean_data, noisy_data)\n",
                "recon_metrics = evaluate_reconstruction(clean_data, reconstructed)\n",
                "\n",
                "print(\"Performance Comparison\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"{'Metric':>20} {'Noisy':>12} {'Reconstructed':>15}\")\n",
                "print(\"-\" * 50)\n",
                "for metric in ['snr', 'psnr', 'ssim', 'mse']:\n",
                "    n_val = noisy_metrics[metric]\n",
                "    r_val = recon_metrics[metric]\n",
                "    improvement = r_val - n_val if metric != 'mse' else n_val - r_val\n",
                "    print(f\"{metric.upper():>20} {n_val:>12.4f} {r_val:>15.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visual comparison\n",
                "trace_idx = 16\n",
                "t = np.arange(metadata['n_samples']) / metadata['sample_rate']\n",
                "\n",
                "fig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True)\n",
                "\n",
                "axes[0].plot(t, clean_data[trace_idx], 'b-', linewidth=0.8)\n",
                "axes[0].set_ylabel('Amplitude')\n",
                "axes[0].set_title('Original Clean Signal')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "axes[1].plot(t, noisy_data[trace_idx], 'r-', linewidth=0.8)\n",
                "axes[1].set_ylabel('Amplitude')\n",
                "axes[1].set_title('Noisy Input')\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "axes[2].plot(t, reconstructed[trace_idx], 'g-', linewidth=0.8)\n",
                "axes[2].set_ylabel('Amplitude')\n",
                "axes[2].set_title('Reconstructed Output')\n",
                "axes[2].grid(True, alpha=0.3)\n",
                "\n",
                "# Overlay\n",
                "axes[3].plot(t, clean_data[trace_idx], 'b-', linewidth=0.8, label='Original', alpha=0.7)\n",
                "axes[3].plot(t, reconstructed[trace_idx], 'g--', linewidth=0.8, label='Reconstructed', alpha=0.7)\n",
                "axes[3].set_xlabel('Time (s)')\n",
                "axes[3].set_ylabel('Amplitude')\n",
                "axes[3].set_title('Comparison')\n",
                "axes[3].legend()\n",
                "axes[3].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Batch Processing with InferenceEngine"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For large datasets, use InferenceEngine with patch-based processing\n",
                "print(\"InferenceEngine Parameters:\")\n",
                "print(\"  - Supports sliding window extraction\")\n",
                "print(\"  - Automatic patch blending\")\n",
                "print(\"  - GPU memory management\")\n",
                "print(\"  - Batch size optimization\")\n",
                "\n",
                "# Example configuration\n",
                "inference_config = {\n",
                "    'patch_size': (64, 64),\n",
                "    'stride': (32, 32),\n",
                "    'batch_size': 16,\n",
                "    'blend_mode': 'linear',\n",
                "}\n",
                "\n",
                "print(f\"\\nExample config: {inference_config}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Summary\n",
                "\n",
                "This notebook demonstrated:\n",
                "\n",
                "1. **U-Net Architecture**: Encoder-decoder with skip connections\n",
                "2. **Pipeline Loading**: Using `SeismicRecoveryPipeline.from_preset()`\n",
                "3. **Inference**: Running recovery on noisy data\n",
                "4. **Evaluation**: Quantitative metrics comparison\n",
                "5. **Batch Processing**: InferenceEngine for large datasets\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "- **06_gan_based_high_fidelity_reconstruction.ipynb**: GAN models\n",
                "- **14_advanced_model_customization_and_training.ipynb**: Custom training"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}