{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Case Study: Real-World Data\n",
    "\n",
    "Workflow for processing real seismic data files.\n",
    "\n",
    "**Prerequisites:** SEG-Y or miniSEED data file\n",
    "\n",
    "**Data Sources:**\n",
    "- IRIS Data Services (https://ds.iris.edu)\n",
    "- USGS Earthquake Hazards (https://earthquake.usgs.gov)\n",
    "- Public seismic datasets on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install promethium-seismic==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promethium\n",
    "from promethium import (\n",
    "    load_segy,\n",
    "    load_miniseed,\n",
    "    SeismicRecoveryPipeline,\n",
    "    evaluate_reconstruction,\n",
    "    bandpass_filter,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "set_seed(42)\n",
    "print(f\"Promethium {promethium.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Replace the path with your actual data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example paths - replace with your data\n",
    "DATA_PATH = './data/survey.sgy'  # or .mseed\n",
    "\n",
    "if os.path.exists(DATA_PATH):\n",
    "    if DATA_PATH.endswith(('.sgy', '.segy')):\n",
    "        data = load_segy(DATA_PATH)\n",
    "    else:\n",
    "        data = load_miniseed(DATA_PATH)\n",
    "    print(f\"Loaded: {data.shape}\")\n",
    "else:\n",
    "    print(f\"Data file not found: {DATA_PATH}\")\n",
    "    print(\"Using synthetic data for demonstration\")\n",
    "    from promethium import generate_synthetic_traces, add_noise\n",
    "    clean, meta = generate_synthetic_traces(n_traces=100, n_samples=1000, seed=42)\n",
    "    data = add_noise(clean, noise_level=0.3, seed=42)\n",
    "    print(f\"Generated: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic QC\n",
    "print(\"Data Statistics:\")\n",
    "print(f\"  Shape: {data.shape}\")\n",
    "print(f\"  Min: {np.min(data):.4f}\")\n",
    "print(f\"  Max: {np.max(data):.4f}\")\n",
    "print(f\"  Mean: {np.mean(data):.4f}\")\n",
    "print(f\"  Std: {np.std(data):.4f}\")\n",
    "\n",
    "# Check for issues\n",
    "nan_count = np.sum(np.isnan(data))\n",
    "inf_count = np.sum(np.isinf(data))\n",
    "print(f\"  NaN values: {nan_count}\")\n",
    "print(f\"  Inf values: {inf_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "fs = 250.0  # Adjust based on your data\n",
    "\n",
    "processed = np.array([\n",
    "    bandpass_filter(trace, lowcut=1.0, highcut=100.0, fs=fs)\n",
    "    for trace in data\n",
    "])\n",
    "\n",
    "print(f\"Preprocessed: {processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pipeline = SeismicRecoveryPipeline.from_preset('unet_denoise_v1')\n",
    "    result = pipeline.run(processed)\n",
    "except Exception as e:\n",
    "    from scipy.ndimage import gaussian_filter1d\n",
    "    result = np.array([gaussian_filter1d(t, sigma=1.5) for t in processed])\n",
    "\n",
    "print(f\"Result: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "clip = np.percentile(np.abs(data), 99)\n",
    "\n",
    "axes[0].imshow(data.T[:500], aspect='auto', cmap='seismic', vmin=-clip, vmax=clip)\n",
    "axes[0].set_title('Input Data')\n",
    "axes[0].set_xlabel('Trace')\n",
    "axes[0].set_ylabel('Sample')\n",
    "\n",
    "axes[1].imshow(result.T[:500], aspect='auto', cmap='seismic', vmin=-clip, vmax=clip)\n",
    "axes[1].set_title('Processed Result')\n",
    "axes[1].set_xlabel('Trace')\n",
    "axes[1].set_ylabel('Sample')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(output_dir, 'processed_data.npy'), result)\n",
    "print(f\"Saved to {output_dir}/processed_data.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Demonstrated workflow for real data:\n",
    "1. Data loading (SEG-Y, miniSEED)\n",
    "2. Quality control\n",
    "3. Preprocessing (filtering)\n",
    "4. Recovery pipeline\n",
    "5. Visualization and export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}