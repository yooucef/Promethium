{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Kaggle and Google Colab Integration\n",
                "\n",
                "This notebook demonstrates how to use Promethium in cloud notebook environments.\n",
                "\n",
                "**Prerequisites:**\n",
                "- Kaggle account or Google Colab access\n",
                "- No local installation required\n",
                "\n",
                "**Estimated Runtime:** 5-10 minutes\n",
                "\n",
                "**Topics Covered:**\n",
                "- Installation in cloud environments\n",
                "- GPU detection and usage\n",
                "- Data path handling for Kaggle and Colab\n",
                "- Memory management tips"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Installation\n",
                "\n",
                "Install Promethium directly from PyPI. This works in both Kaggle and Colab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Promethium from PyPI\n",
                "!pip install promethium-seismic==1.0.1 -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify installation\n",
                "import promethium\n",
                "print(f\"Promethium version: {promethium.__version__}\")\n",
                "\n",
                "# Import all needed functions\n",
                "from promethium import (\n",
                "    load_segy,\n",
                "    SeismicRecoveryPipeline,\n",
                "    evaluate_reconstruction,\n",
                "    generate_synthetic_traces,\n",
                "    add_noise,\n",
                "    set_seed,\n",
                "    get_device,\n",
                "    run_recovery,\n",
                ")\n",
                "\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Environment Detection\n",
                "\n",
                "Detect whether we are running in Kaggle, Colab, or a local environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "def detect_environment():\n",
                "    \"\"\"Detect the current execution environment.\"\"\"\n",
                "    if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
                "        return 'kaggle'\n",
                "    elif 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules:\n",
                "        return 'colab'\n",
                "    else:\n",
                "        return 'local'\n",
                "\n",
                "environment = detect_environment()\n",
                "print(f\"Environment: {environment}\")\n",
                "\n",
                "# Device detection\n",
                "device = get_device()\n",
                "print(f\"Compute device: {device}\")\n",
                "\n",
                "# Check GPU availability\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "else:\n",
                "    print(\"GPU: Not available (using CPU)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Paths\n",
                "\n",
                "Configure data paths based on the environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_data_paths(environment):\n",
                "    \"\"\"Get input and output paths based on environment.\"\"\"\n",
                "    if environment == 'kaggle':\n",
                "        input_dir = '/kaggle/input'\n",
                "        output_dir = '/kaggle/working'\n",
                "    elif environment == 'colab':\n",
                "        input_dir = '/content'\n",
                "        output_dir = '/content'\n",
                "    else:\n",
                "        input_dir = './data'\n",
                "        output_dir = './output'\n",
                "    \n",
                "    return input_dir, output_dir\n",
                "\n",
                "input_dir, output_dir = get_data_paths(environment)\n",
                "print(f\"Input directory: {input_dir}\")\n",
                "print(f\"Output directory: {output_dir}\")\n",
                "\n",
                "# Create output directory if it does not exist\n",
                "os.makedirs(output_dir, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Loading Data\n",
                "\n",
                "### Option A: From Kaggle Dataset\n",
                "```python\n",
                "# Example for Kaggle\n",
                "data = load_segy('/kaggle/input/seismic-dataset/survey.sgy')\n",
                "```\n",
                "\n",
                "### Option B: Upload to Colab\n",
                "```python\n",
                "# Upload file in Colab\n",
                "from google.colab import files\n",
                "uploaded = files.upload()\n",
                "data = load_segy(list(uploaded.keys())[0])\n",
                "```\n",
                "\n",
                "### Option C: Generate Synthetic Data (Demo)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For demonstration, generate synthetic data\n",
                "set_seed(42)\n",
                "\n",
                "clean_data, metadata = generate_synthetic_traces(\n",
                "    n_traces=100,\n",
                "    n_samples=500,\n",
                "    sample_rate=250.0,\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "# Add noise\n",
                "noisy_data = add_noise(clean_data, noise_level=0.25, seed=42)\n",
                "\n",
                "print(f\"Data shape: {noisy_data.shape}\")\n",
                "print(f\"Memory usage: {noisy_data.nbytes / 1024:.2f} KB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Run Recovery Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the convenience function for quick recovery\n",
                "try:\n",
                "    reconstructed = run_recovery(noisy_data, preset='unet_denoise_v1')\n",
                "except Exception as e:\n",
                "    print(f\"Note: Full model requires trained weights.\")\n",
                "    print(f\"Using simple filter for demonstration.\")\n",
                "    from scipy.ndimage import gaussian_filter1d\n",
                "    reconstructed = np.array([gaussian_filter1d(trace, sigma=2) for trace in noisy_data])\n",
                "\n",
                "print(f\"Reconstructed shape: {reconstructed.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluate and Visualize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute metrics\n",
                "metrics = evaluate_reconstruction(clean_data, reconstructed)\n",
                "\n",
                "print(\"Reconstruction Metrics:\")\n",
                "for name, value in metrics.items():\n",
                "    print(f\"  {name}: {value:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize results\n",
                "trace_idx = 25\n",
                "t = np.arange(metadata['n_samples']) / metadata['sample_rate']\n",
                "\n",
                "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
                "\n",
                "axes[0].plot(t, clean_data[trace_idx], 'b-', linewidth=0.8)\n",
                "axes[0].set_ylabel('Amplitude')\n",
                "axes[0].set_title('Original Clean')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "axes[1].plot(t, noisy_data[trace_idx], 'r-', linewidth=0.8)\n",
                "axes[1].set_ylabel('Amplitude')\n",
                "axes[1].set_title('Noisy Input')\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "axes[2].plot(t, reconstructed[trace_idx], 'g-', linewidth=0.8)\n",
                "axes[2].set_xlabel('Time (s)')\n",
                "axes[2].set_ylabel('Amplitude')\n",
                "axes[2].set_title('Reconstructed')\n",
                "axes[2].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(output_dir, 'reconstruction_result.png'), dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print(f\"Figure saved to: {os.path.join(output_dir, 'reconstruction_result.png')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Memory Management Tips\n",
                "\n",
                "Cloud environments have limited memory. Here are tips for efficient usage:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check available memory\n",
                "import psutil\n",
                "\n",
                "memory = psutil.virtual_memory()\n",
                "print(f\"Total RAM: {memory.total / 1e9:.1f} GB\")\n",
                "print(f\"Available RAM: {memory.available / 1e9:.1f} GB\")\n",
                "print(f\"Used RAM: {memory.percent:.1f}%\")\n",
                "\n",
                "# Tips for memory management\n",
                "print(\"\\nMemory Management Tips:\")\n",
                "print(\"1. Process data in chunks for large datasets\")\n",
                "print(\"2. Delete intermediate variables with 'del variable'\")\n",
                "print(\"3. Use float32 instead of float64 when possible\")\n",
                "print(\"4. Clear GPU memory with torch.cuda.empty_cache()\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Saving Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save reconstructed data as numpy file\n",
                "output_path = os.path.join(output_dir, 'reconstructed_data.npy')\n",
                "np.save(output_path, reconstructed)\n",
                "print(f\"Data saved to: {output_path}\")\n",
                "\n",
                "# Save metrics as JSON\n",
                "import json\n",
                "metrics_path = os.path.join(output_dir, 'metrics.json')\n",
                "with open(metrics_path, 'w') as f:\n",
                "    json.dump(metrics, f, indent=2)\n",
                "print(f\"Metrics saved to: {metrics_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Summary\n",
                "\n",
                "This notebook demonstrated:\n",
                "\n",
                "1. **Installation**: `pip install promethium-seismic==1.0.1`\n",
                "2. **Environment Detection**: Kaggle, Colab, or local\n",
                "3. **GPU Usage**: Automatic device detection\n",
                "4. **Data Paths**: Environment-specific path handling\n",
                "5. **Memory Management**: Tips for cloud environments\n",
                "6. **Result Saving**: Export to numpy and JSON formats\n",
                "\n",
                "### Kaggle Competition Template\n",
                "\n",
                "```python\n",
                "!pip install promethium-seismic==1.0.1 -q\n",
                "\n",
                "from promethium import load_segy, run_recovery, evaluate_reconstruction\n",
                "\n",
                "# Load competition data\n",
                "data = load_segy('/kaggle/input/competition-name/test.sgy')\n",
                "\n",
                "# Run recovery\n",
                "result = run_recovery(data, preset='unet_denoise_v1')\n",
                "\n",
                "# Save submission\n",
                "import numpy as np\n",
                "np.save('/kaggle/working/submission.npy', result)\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}