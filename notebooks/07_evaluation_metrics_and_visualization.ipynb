{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics and Visualization\n",
    "\n",
    "This notebook provides a comprehensive guide to evaluating seismic reconstruction quality.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python 3.10+\n",
    "- Basic understanding of signal quality metrics\n",
    "\n",
    "**Estimated Runtime:** 5 minutes\n",
    "\n",
    "**Metrics Covered:**\n",
    "- Signal-to-Noise Ratio (SNR)\n",
    "- Mean Squared Error (MSE)\n",
    "- Peak Signal-to-Noise Ratio (PSNR)\n",
    "- Structural Similarity Index (SSIM)\n",
    "- Frequency Domain Correlation\n",
    "- Phase Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install:\n",
    "# !pip install promethium-seismic==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promethium\n",
    "from promethium import (\n",
    "    signal_to_noise_ratio,\n",
    "    mean_squared_error,\n",
    "    peak_signal_to_noise_ratio,\n",
    "    structural_similarity_index,\n",
    "    frequency_domain_correlation,\n",
    "    phase_coherence,\n",
    "    evaluate_reconstruction,\n",
    "    generate_synthetic_traces,\n",
    "    add_noise,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"Promethium version: {promethium.__version__}\")\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Test Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean data\n",
    "clean_data, metadata = generate_synthetic_traces(\n",
    "    n_traces=50,\n",
    "    n_samples=500,\n",
    "    sample_rate=250.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create multiple degradation scenarios\n",
    "scenarios = {\n",
    "    'low_noise': add_noise(clean_data, noise_level=0.1, seed=42),\n",
    "    'medium_noise': add_noise(clean_data, noise_level=0.3, seed=42),\n",
    "    'high_noise': add_noise(clean_data, noise_level=0.5, seed=42),\n",
    "}\n",
    "\n",
    "# Simulate reconstructions (with decreasing quality)\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "reconstructions = {\n",
    "    'good_recovery': np.array([gaussian_filter1d(t, sigma=1) for t in scenarios['medium_noise']]),\n",
    "    'moderate_recovery': np.array([gaussian_filter1d(t, sigma=3) for t in scenarios['medium_noise']]),\n",
    "    'poor_recovery': np.array([gaussian_filter1d(t, sigma=6) for t in scenarios['medium_noise']]),\n",
    "}\n",
    "\n",
    "print(f\"Created {len(scenarios)} noise scenarios and {len(reconstructions)} reconstruction scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute individual metrics for demonstration\n",
    "y_true = clean_data[0:1]  # Single trace\n",
    "y_pred = reconstructions['good_recovery'][0:1]\n",
    "\n",
    "print(\"Individual Metric Examples\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# SNR\n",
    "snr = signal_to_noise_ratio(y_true, y_pred)\n",
    "print(f\"SNR: {snr:.2f} dB\")\n",
    "print(\"  Higher is better. Measures signal power vs noise power.\")\n",
    "print()\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(\"  Lower is better. Average squared difference.\")\n",
    "print()\n",
    "\n",
    "# PSNR\n",
    "psnr = peak_signal_to_noise_ratio(y_true, y_pred)\n",
    "print(f\"PSNR: {psnr:.2f} dB\")\n",
    "print(\"  Higher is better. Peak signal vs noise ratio.\")\n",
    "print()\n",
    "\n",
    "# SSIM\n",
    "ssim = structural_similarity_index(y_true, y_pred)\n",
    "print(f\"SSIM: {ssim:.4f}\")\n",
    "print(\"  Range [-1, 1]. 1 = perfect similarity.\")\n",
    "print()\n",
    "\n",
    "# Frequency Domain Correlation\n",
    "freq_corr = frequency_domain_correlation(y_true, y_pred)\n",
    "print(f\"Frequency Correlation: {freq_corr:.4f}\")\n",
    "print(\"  Range [-1, 1]. 1 = perfect frequency match.\")\n",
    "print()\n",
    "\n",
    "# Phase Coherence\n",
    "phase_coh = phase_coherence(y_true, y_pred)\n",
    "print(f\"Phase Coherence: {phase_coh:.4f}\")\n",
    "print(\"  Range [0, 1]. 1 = perfect phase preservation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all reconstruction scenarios\n",
    "results = []\n",
    "\n",
    "for name, recon in reconstructions.items():\n",
    "    metrics = evaluate_reconstruction(clean_data, recon)\n",
    "    metrics['scenario'] = name\n",
    "    results.append(metrics)\n",
    "\n",
    "# Create DataFrame for easy comparison\n",
    "df = pd.DataFrame(results)\n",
    "df = df.set_index('scenario')\n",
    "\n",
    "print(\"Reconstruction Quality Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metrics comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "metrics_to_plot = ['snr', 'mse', 'psnr', 'ssim', 'freq_correlation', 'phase_coherence']\n",
    "\n",
    "for ax, metric in zip(axes.flatten(), metrics_to_plot):\n",
    "    values = df[metric].values\n",
    "    bars = ax.bar(df.index, values, color=['green', 'orange', 'red'])\n",
    "    ax.set_title(metric.upper().replace('_', ' '))\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of reconstruction quality\n",
    "trace_idx = 10\n",
    "t = np.arange(metadata['n_samples']) / metadata['sample_rate']\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(14, 12), sharex=True)\n",
    "\n",
    "# Original\n",
    "axes[0].plot(t, clean_data[trace_idx], 'b-', linewidth=0.8)\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].set_title('Original Clean Signal')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Noisy input\n",
    "axes[1].plot(t, scenarios['medium_noise'][trace_idx], 'r-', linewidth=0.8)\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "axes[1].set_title('Noisy Input (30% noise)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Reconstructions\n",
    "colors = ['green', 'orange', 'brown']\n",
    "for i, (name, recon) in enumerate(reconstructions.items()):\n",
    "    ax = axes[i + 2]\n",
    "    ax.plot(t, recon[trace_idx], color=colors[i], linewidth=0.8)\n",
    "    snr_val = df.loc[name, 'snr']\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.set_title(f'{name.replace(\"_\", \" \").title()} (SNR: {snr_val:.1f} dB)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Error Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and visualize error maps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "for i, (name, recon) in enumerate(reconstructions.items()):\n",
    "    error = clean_data - recon\n",
    "    \n",
    "    clip = np.percentile(np.abs(error), 99)\n",
    "    im = axes[i].imshow(\n",
    "        error.T[:200, :],  # Show first 200 time samples\n",
    "        aspect='auto',\n",
    "        cmap='coolwarm',\n",
    "        vmin=-clip,\n",
    "        vmax=clip\n",
    "    )\n",
    "    axes[i].set_xlabel('Trace')\n",
    "    axes[i].set_ylabel('Time Sample')\n",
    "    axes[i].set_title(f'Error Map: {name.replace(\"_\", \" \").title()}')\n",
    "\n",
    "plt.colorbar(im, ax=axes, label='Error Amplitude', shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Individual Metrics**: SNR, MSE, PSNR, SSIM, frequency correlation, phase coherence\n",
    "2. **Comprehensive Evaluation**: Using `evaluate_reconstruction()` for all metrics\n",
    "3. **Comparative Analysis**: Tabular and visual comparison of scenarios\n",
    "4. **Error Visualization**: Error maps for spatial analysis\n",
    "\n",
    "### Metric Selection Guidelines\n",
    "\n",
    "| Use Case | Recommended Metrics |\n",
    "|----------|--------------------|\n",
    "| General quality | SNR, PSNR |\n",
    "| Perceptual similarity | SSIM |\n",
    "| Frequency preservation | Frequency Correlation |\n",
    "| Phase-sensitive applications | Phase Coherence |\n",
    "| Optimization target | MSE, PSNR |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}