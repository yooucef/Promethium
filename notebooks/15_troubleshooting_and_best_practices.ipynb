{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troubleshooting and Best Practices\n",
    "\n",
    "This notebook collects common issues, solutions, and best practices for using Promethium.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python 3.10+\n",
    "- Some experience with Promethium\n",
    "\n",
    "**Topics Covered:**\n",
    "- Common error patterns\n",
    "- Diagnostic utilities\n",
    "- Performance optimization\n",
    "- Best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install:\n",
    "# !pip install promethium-seismic==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promethium\n",
    "print(f\"Promethium version: {promethium.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"System Information\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory check\n",
    "import psutil\n",
    "\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"RAM Total: {mem.total / 1e9:.1f} GB\")\n",
    "print(f\"RAM Available: {mem.available / 1e9:.1f} GB\")\n",
    "print(f\"RAM Used: {mem.percent:.1f}%\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory\n",
    "    print(f\"GPU Memory: {gpu_mem / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Common Issues and Solutions\n",
    "\n",
    "### Issue 1: Shape Mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: Data has wrong dimensions\n",
    "# Solution: Check and reshape\n",
    "\n",
    "def check_data_shape(data, expected_ndim=2):\n",
    "    \"\"\"Validate data shape and provide diagnostics.\"\"\"\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(f\"Data ndim: {data.ndim}\")\n",
    "    print(f\"Data dtype: {data.dtype}\")\n",
    "    \n",
    "    if data.ndim != expected_ndim:\n",
    "        print(f\"WARNING: Expected {expected_ndim}D, got {data.ndim}D\")\n",
    "        if data.ndim == 1:\n",
    "            print(\"  Suggestion: data = data.reshape(1, -1)\")\n",
    "        elif data.ndim == 3:\n",
    "            print(\"  Suggestion: data = data.squeeze()\")\n",
    "    else:\n",
    "        print(\"OK: Shape is correct\")\n",
    "\n",
    "# Example\n",
    "from promethium import generate_synthetic_traces\n",
    "data, _ = generate_synthetic_traces(n_traces=10, n_samples=100)\n",
    "check_data_shape(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 2: NaN or Inf Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_validity(data):\n",
    "    \"\"\"Check for NaN and Inf values.\"\"\"\n",
    "    nan_count = np.sum(np.isnan(data))\n",
    "    inf_count = np.sum(np.isinf(data))\n",
    "    \n",
    "    print(f\"NaN values: {nan_count}\")\n",
    "    print(f\"Inf values: {inf_count}\")\n",
    "    \n",
    "    if nan_count > 0 or inf_count > 0:\n",
    "        print(\"WARNING: Invalid values detected\")\n",
    "        print(\"  Solution: data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\")\n",
    "    else:\n",
    "        print(\"OK: No invalid values\")\n",
    "    \n",
    "    return nan_count == 0 and inf_count == 0\n",
    "\n",
    "check_data_validity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 3: GPU Memory Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory cache.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"GPU memory cache cleared\")\n",
    "        \n",
    "        # Report current usage\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        print(f\"Allocated: {allocated:.2f} GB\")\n",
    "        print(f\"Reserved: {reserved:.2f} GB\")\n",
    "    else:\n",
    "        print(\"No GPU available\")\n",
    "\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_operation(func, *args, n_runs=5, **kwargs):\n",
    "    \"\"\"Benchmark an operation.\"\"\"\n",
    "    times = []\n",
    "    \n",
    "    for _ in range(n_runs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        times.append(end - start)\n",
    "    \n",
    "    print(f\"Mean time: {np.mean(times)*1000:.2f} ms\")\n",
    "    print(f\"Std time: {np.std(times)*1000:.2f} ms\")\n",
    "    print(f\"Min time: {np.min(times)*1000:.2f} ms\")\n",
    "    print(f\"Max time: {np.max(times)*1000:.2f} ms\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example benchmark\n",
    "from promethium import bandpass_filter\n",
    "print(\"Benchmarking bandpass filter:\")\n",
    "_ = benchmark_operation(bandpass_filter, data[0], lowcut=5, highcut=50, fs=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Best Practices Summary\n",
    "\n",
    "### Data Handling\n",
    "1. Always validate data shape and dtype before processing\n",
    "2. Use float32 for memory efficiency\n",
    "3. Check for NaN/Inf values after operations\n",
    "\n",
    "### Memory Management\n",
    "1. Process large datasets in chunks\n",
    "2. Delete intermediate variables with `del`\n",
    "3. Call `torch.cuda.empty_cache()` after GPU operations\n",
    "\n",
    "### Reproducibility\n",
    "1. Always call `set_seed()` at the start\n",
    "2. Document library versions\n",
    "3. Save both data and configuration\n",
    "\n",
    "### Performance\n",
    "1. Use GPU when available\n",
    "2. Batch processing for multiple traces\n",
    "3. Profile before optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for reproducible experiments\n",
    "print(\"Reproducible Experiment Template:\")\n",
    "print(\"\"\"\n",
    "# 1. Set random seeds\n",
    "from promethium import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "# 2. Document versions\n",
    "import promethium\n",
    "print(f\"Promethium: {promethium.__version__}\")\n",
    "\n",
    "# 3. Configure device\n",
    "from promethium import get_device\n",
    "device = get_device()\n",
    "\n",
    "# 4. Load and validate data\n",
    "data = load_your_data()\n",
    "assert data.shape == expected_shape\n",
    "assert not np.any(np.isnan(data))\n",
    "\n",
    "# 5. Run pipeline\n",
    "pipeline = SeismicRecoveryPipeline.from_preset('...')\n",
    "result = pipeline.run(data)\n",
    "\n",
    "# 6. Evaluate and save\n",
    "metrics = evaluate_reconstruction(ground_truth, result)\n",
    "np.save('results.npy', result)\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}