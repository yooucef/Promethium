{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# End-to-End Case Study: Synthetic Data\n",
                "\n",
                "A complete workflow example using synthetic seismic data.\n",
                "\n",
                "**Prerequisites:** Python 3.10+, notebook 01 completed\n",
                "\n",
                "**Estimated Runtime:** 10 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install promethium-seismic==1.0.1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import promethium\n",
                "from promethium import (\n",
                "    SeismicRecoveryPipeline,\n",
                "    evaluate_reconstruction,\n",
                "    generate_synthetic_traces,\n",
                "    add_noise,\n",
                "    bandpass_filter,\n",
                "    set_seed,\n",
                "    get_device,\n",
                ")\n",
                "from promethium.utils.synthetic import create_missing_traces\n",
                "\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "set_seed(42)\n",
                "device = get_device()\n",
                "print(f\"Promethium {promethium.__version__} | Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Generate Synthetic Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate layered synthetic data\n",
                "clean_data, metadata = generate_synthetic_traces(\n",
                "    n_traces=128,\n",
                "    n_samples=512,\n",
                "    sample_rate=250.0,\n",
                "    frequencies=[5.0, 15.0, 30.0, 50.0],\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "print(f\"Dataset: {clean_data.shape[0]} traces x {clean_data.shape[1]} samples\")\n",
                "print(f\"Duration: {metadata['duration']:.2f} s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Corrupt Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add noise\n",
                "noisy_data = add_noise(clean_data, noise_level=0.25, seed=42)\n",
                "\n",
                "# Create missing traces\n",
                "corrupted_data, mask = create_missing_traces(noisy_data, missing_ratio=0.2, seed=42)\n",
                "\n",
                "print(f\"Added 25% noise\")\n",
                "print(f\"Missing traces: {int(np.sum(mask == 0))} ({20}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply bandpass filter to reduce noise\n",
                "preprocessed = np.array([\n",
                "    bandpass_filter(trace, lowcut=2.0, highcut=80.0, fs=metadata['sample_rate'])\n",
                "    for trace in corrupted_data\n",
                "])\n",
                "\n",
                "print(f\"Preprocessed shape: {preprocessed.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Recovery Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run recovery\n",
                "try:\n",
                "    pipeline = SeismicRecoveryPipeline.from_preset('unet_denoise_v1')\n",
                "    reconstructed = pipeline.run(preprocessed)\n",
                "except Exception:\n",
                "    from scipy.ndimage import gaussian_filter1d\n",
                "    reconstructed = np.array([gaussian_filter1d(t, sigma=1.5) for t in preprocessed])\n",
                "\n",
                "print(f\"Reconstructed: {reconstructed.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "metrics_corrupted = evaluate_reconstruction(clean_data, corrupted_data)\n",
                "metrics_recovered = evaluate_reconstruction(clean_data, reconstructed)\n",
                "\n",
                "print(f\"{'Stage':>15} {'SNR (dB)':>12} {'SSIM':>10}\")\n",
                "print(\"-\" * 40)\n",
                "print(f\"{'Corrupted':>15} {metrics_corrupted['snr']:>12.2f} {metrics_corrupted['ssim']:>10.4f}\")\n",
                "print(f\"{'Recovered':>15} {metrics_recovered['snr']:>12.2f} {metrics_recovered['ssim']:>10.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "clip = np.percentile(np.abs(clean_data), 99)\n",
                "\n",
                "for ax, (title, data) in zip(axes.flatten(), [\n",
                "    ('Original', clean_data),\n",
                "    ('Corrupted', corrupted_data),\n",
                "    ('Preprocessed', preprocessed),\n",
                "    ('Reconstructed', reconstructed)\n",
                "]):\n",
                "    ax.imshow(data.T[:200], aspect='auto', cmap='seismic', vmin=-clip, vmax=clip)\n",
                "    ax.set_title(title)\n",
                "    ax.set_xlabel('Trace')\n",
                "    ax.set_ylabel('Sample')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "Complete workflow demonstrated:\n",
                "1. Data generation\n",
                "2. Corruption (noise + missing traces)\n",
                "3. Preprocessing (filtering)\n",
                "4. Recovery (pipeline)\n",
                "5. Quantitative evaluation"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}